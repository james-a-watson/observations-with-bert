{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to take the initial model produced by model_train.ipynb and use the same functionality to train over more labelled records. This will build on the weights that are currently set in the model and further tune them by exposing the model to more data.\n",
    "\n",
    "You should be able to run this over and over again and see better and better results on the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import numpy as np\n",
    "from data_helpers import feature_prep, split_sample\n",
    "from model import load_ckp, BERTClass, train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to your favorite model here. Note that models are saved to a warm_start folder to prevent confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = \"best_model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set our device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): # check for CUDA gpu\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): #Â Check for Apple M1/M2 chip\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # Otherwise just use CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Once the optimizer has been through a few epochs the learning rate is so small that no significant improvements are made in the results. To rectify this I have been reseting the optimizer here rather than using the one loaded from the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "optimizer_init = torch.optim.Adam()\n",
    "checkpoint_path = \"warm_start/current_checkpoint.pt\"\n",
    "best_model = \"warm_start/best_model.pt\"\n",
    "valid_loss_min_input = np.Inf\n",
    "model, optimizer, epoch, valid_loss_min_input = load_ckp(load_model, model, optimizer_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells we will take a cut of the remaining unseen observations ready for training and remove those recrods from the unseen data to avoid picking them out again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"observation_categories.json\", \"r\") as f:\n",
    "    categories = json.load(f)[\"categories\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** observation_categories.json and observations_unseen.csv should have been created by model_train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv(\"observations-unseen.csv\")\n",
    "print(f\"FULL Dataset: {model.shape}\")\n",
    "display(model_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a sample of the unseen data that we have loaded in for training our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 50000\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "sample_data = model_data.sample(SAMPLE_SIZE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
